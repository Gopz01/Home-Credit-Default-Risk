{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f865e20-6698-43bb-8607-49658f114fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-20 07:42:31,525 - INFO - Notebook 04 Initialized.\n"
     ]
    }
   ],
   "source": [
    "# --- NOTEBOOK 04: FEATURE ENGINEERING ---\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "import gc\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class Config:\n",
    "    INPUT_PATH = 'clean_train.parquet' # From NB 01 (Clean but Raw)\n",
    "    OUTPUT_PATH = 'engineered_data.parquet'\n",
    "    \n",
    "    # Feature Groups\n",
    "    # We define what we want to build\n",
    "    CREATE_RATIOS = True\n",
    "    AGGREGATE_EXT_SOURCES = True\n",
    "    ENCODE_CATEGORICALS = True\n",
    "\n",
    "logger.info(\"Notebook 04 Initialized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e95b3c57-ec43-414e-9665-4ec0bd147dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DomainEngineer:\n",
    "    \"\"\"\n",
    "    Creates financial ratios used in credit scoring.\n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    def create_financial_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "        logger.info(\"Engineering Financial Ratios...\")\n",
    "        \n",
    "        # 1. CREDIT TERM (How long to pay back?)\n",
    "        # Credit / Annuity = Roughly the length of the loan in years (if interest was 0)\n",
    "        df['NEW_CREDIT_TO_ANNUITY_RATIO'] = df['AMT_CREDIT'] / df['AMT_ANNUITY']\n",
    "        \n",
    "        # 2. CREDIT POWER (Loan vs Income)\n",
    "        # Did you borrow 10x your salary?\n",
    "        df['NEW_CREDIT_TO_INCOME_RATIO'] = df['AMT_CREDIT'] / df['AMT_INCOME_TOTAL']\n",
    "        \n",
    "        # 3. DEBT BURDEN (Annuity vs Income)\n",
    "        # What % of paycheck goes to loan?\n",
    "        df['NEW_ANNUITY_TO_INCOME_RATIO'] = df['AMT_ANNUITY'] / df['AMT_INCOME_TOTAL']\n",
    "        \n",
    "        # 4. GOODS VALUATION (Loan vs Goods Price)\n",
    "        # Did you borrow MORE than the car is worth? (Insurance/Fees)\n",
    "        # Note: We dropped AMT_GOODS_PRICE in NB 02 (Linear), but Trees love this ratio.\n",
    "        if 'AMT_GOODS_PRICE' in df.columns:\n",
    "            df['NEW_CREDIT_TO_GOODS_RATIO'] = df['AMT_CREDIT'] / df['AMT_GOODS_PRICE']\n",
    "        \n",
    "        # 5. EMPLOYMENT STABILITY\n",
    "        # What % of your life have you worked?\n",
    "        # (DAYS_EMPLOYED is negative, DAYS_BIRTH is negative)\n",
    "        df['NEW_EMPLOYED_TO_BIRTH_RATIO'] = df['DAYS_EMPLOYED'] / df['DAYS_BIRTH']\n",
    "        \n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16f38c82-e1ae-4d1e-a3e6-6eb2684572c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolymathEngineer:\n",
    "    \"\"\"\n",
    "    Aggregates groups of features into summary statistics.\n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    def aggregate_ext_sources(df: pd.DataFrame) -> pd.DataFrame:\n",
    "        logger.info(\"Aggregating External Sources...\")\n",
    "        \n",
    "        ext_cols = ['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']\n",
    "        \n",
    "        # Row-wise operations\n",
    "        # Mean: The \"Average Trust\"\n",
    "        df['NEW_EXT_SOURCES_MEAN'] = df[ext_cols].mean(axis=1)\n",
    "        \n",
    "        # Std: The \"Disagreement\" (High std = One bureau likes you, one hates you)\n",
    "        df['NEW_EXT_SOURCES_STD'] = df[ext_cols].std(axis=1)\n",
    "        \n",
    "        # Min: The \"Worst Case\" (Risk models often care about the lowest score)\n",
    "        df['NEW_EXT_SOURCES_MIN'] = df[ext_cols].min(axis=1)\n",
    "        \n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f060e633-297a-4d14-8d29-c21a8411c0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CategoricalEngineer:\n",
    "    \"\"\"\n",
    "    Handles Categorical Encoding for Tree Models (Label Encoding).\n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    def label_encode(df: pd.DataFrame) -> pd.DataFrame:\n",
    "        logger.info(\"Label Encoding Categoricals...\")\n",
    "        \n",
    "        # Select object columns\n",
    "        # Note: We strictly encode ONLY objects. \n",
    "        # We do NOT touch flags (0/1) or integers.\n",
    "        obj_cols = df.select_dtypes(include=['object', 'category']).columns\n",
    "        \n",
    "        le = LabelEncoder()\n",
    "        \n",
    "        for col in obj_cols:\n",
    "            # Fill missing with specific string so Encoder doesn't crash\n",
    "            # We treat 'NaN' as a category itself!\n",
    "            df[col] = df[col].astype(str).fillna('MISSING')\n",
    "            \n",
    "            # Encode\n",
    "            df[col] = le.fit_transform(df[col])\n",
    "            \n",
    "            # Convert to category type (LightGBM loves this)\n",
    "            df[col] = df[col].astype('category')\n",
    "            \n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b98ec67e-0145-4084-b87d-c11e6ff1f19c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-20 07:43:37,432 - INFO - Loading clean_train.parquet...\n",
      "2026-01-20 07:43:37,973 - INFO - Engineering Financial Ratios...\n",
      "2026-01-20 07:43:37,994 - INFO - Aggregating External Sources...\n",
      "2026-01-20 07:43:38,217 - INFO - Label Encoding Categoricals...\n",
      "2026-01-20 07:43:40,210 - INFO - Saving Engineered Data to engineered_data.parquet...\n",
      "2026-01-20 07:43:41,850 - INFO - Final Shape: (307506, 131)\n"
     ]
    }
   ],
   "source": [
    "def run_feature_foundry():\n",
    "    # 1. Load Clean Data (From NB 01)\n",
    "    # We do NOT use the VIF-dropped data from NB 02. Trees can handle redundancy.\n",
    "    # We go back to the source: clean_train.parquet\n",
    "    logger.info(f\"Loading {Config.INPUT_PATH}...\")\n",
    "    df = pd.read_parquet(Config.INPUT_PATH)\n",
    "    \n",
    "    # 2. Domain Features\n",
    "    if Config.CREATE_RATIOS:\n",
    "        df = DomainEngineer.create_financial_features(df)\n",
    "        \n",
    "    # 3. Polymath Features\n",
    "    if Config.AGGREGATE_EXT_SOURCES:\n",
    "        df = PolymathEngineer.aggregate_ext_sources(df)\n",
    "        \n",
    "    # 4. Encoding\n",
    "    if Config.ENCODE_CATEGORICALS:\n",
    "        df = CategoricalEngineer.label_encode(df)\n",
    "        \n",
    "    # 5. Save\n",
    "    logger.info(f\"Saving Engineered Data to {Config.OUTPUT_PATH}...\")\n",
    "    df.to_parquet(Config.OUTPUT_PATH, index=False)\n",
    "    \n",
    "    logger.info(f\"Final Shape: {df.shape}\")\n",
    "    return df\n",
    "\n",
    "# Execute\n",
    "df_engineered = run_feature_foundry()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1e6a8b-d6b3-48bc-b949-cc9117dc3c17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
