{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec7859d0-bd33-4f53-8c1a-9dda50bcbc66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: optuna in c:\\users\\gopala.v.lv\\appdata\\roaming\\python\\python313\\site-packages (4.7.0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in c:\\users\\gopala.v.lv\\appdata\\roaming\\python\\python313\\site-packages (from optuna) (1.18.1)\n",
      "Requirement already satisfied: colorlog in c:\\users\\gopala.v.lv\\appdata\\roaming\\python\\python313\\site-packages (from optuna) (6.10.1)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from optuna) (2.3.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from optuna) (25.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from optuna) (2.0.43)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from optuna) (4.67.1)\n",
      "Requirement already satisfied: PyYAML in c:\\programdata\\anaconda3\\lib\\site-packages (from optuna) (6.0.3)\n",
      "Requirement already satisfied: Mako in c:\\users\\gopala.v.lv\\appdata\\roaming\\python\\python313\\site-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
      "Requirement already satisfied: typing-extensions>=4.12 in c:\\programdata\\anaconda3\\lib\\site-packages (from alembic>=1.5.0->optuna) (4.15.0)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\programdata\\anaconda3\\lib\\site-packages (from sqlalchemy>=1.4.2->optuna) (3.2.4)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from colorlog->optuna) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "# !pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fe3621b-59c6-4b35-859c-17a349717e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-20 17:12:17,024 - INFO - Notebook 08 Initialized.\n"
     ]
    }
   ],
   "source": [
    "# --- NOTEBOOK 08: HYPERPARAMETER TUNING ---\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna  \n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import logging\n",
    "import gc\n",
    "\n",
    "# Logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class Config:\n",
    "    INPUT_PATH = 'train_full_merged.parquet'\n",
    "    SEED = 42\n",
    "    N_FOLDS = 5\n",
    "    # We reduce rows for Tuning to speed it up (Optional but recommended)\n",
    "    # If you have a powerful machine, set this to False\n",
    "    SUBSAMPLE_FOR_TUNING = True \n",
    "    SUBSAMPLE_SIZE = 50000 \n",
    "\n",
    "logger.info(\"Notebook 08 Initialized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01d419df-722a-4f3e-a0b6-ab7f13deb903",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial, X, y):\n",
    "    # 1. Define the Search Space\n",
    "    # Optuna will pick a value from these ranges\n",
    "    param_grid = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'n_estimators': 2000,\n",
    "        'learning_rate': 0.05, # Fixed for tuning speed (we lower it for final run)\n",
    "        'verbosity': -1,\n",
    "        'random_state': Config.SEED,\n",
    "        'n_jobs': 4,\n",
    "        \n",
    "        # TUNING PARAMETERS\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 100),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 10, 100),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0.1, 10.0, log=True),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0.1, 10.0, log=True),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "    }\n",
    "    \n",
    "    # 2. Cross Validation (3-Fold is enough for tuning, 5 is better but slower)\n",
    "    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=Config.SEED)\n",
    "    scores = []\n",
    "    \n",
    "    for train_idx, val_idx in cv.split(X, y):\n",
    "        X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
    "        X_val, y_val = X.iloc[val_idx], y.iloc[val_idx]\n",
    "        \n",
    "        # Train with Early Stopping\n",
    "        model = lgb.LGBMClassifier(**param_grid)\n",
    "        callbacks = [lgb.early_stopping(stopping_rounds=50, verbose=False)]\n",
    "        \n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_val, y_val)],\n",
    "            eval_metric='auc',\n",
    "            callbacks=callbacks\n",
    "        )\n",
    "        \n",
    "        preds = model.predict_proba(X_val)[:, 1]\n",
    "        scores.append(roc_auc_score(y_val, preds))\n",
    "    \n",
    "    # Return Mean AUC\n",
    "    return np.mean(scores)\n",
    "\n",
    "def run_tuning():\n",
    "    logger.info(\"Loading Data...\")\n",
    "    df = pd.read_parquet(Config.INPUT_PATH)\n",
    "    \n",
    "    X = df.drop(columns=['TARGET', 'SK_ID_CURR'])\n",
    "    y = df['TARGET']\n",
    "    \n",
    "    # Subsample for Speed?\n",
    "    if Config.SUBSAMPLE_FOR_TUNING:\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        X, _, y, _ = train_test_split(X, y, train_size=Config.SUBSAMPLE_SIZE, stratify=y, random_state=Config.SEED)\n",
    "        logger.info(f\"Tuning on subsample: {X.shape}\")\n",
    "        \n",
    "    logger.info(\"Starting Optuna Study...\")\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(lambda trial: objective(trial, X, y), n_trials=30) # Run 30 trials\n",
    "    \n",
    "    logger.info(\"--- BEST PARAMETERS ---\")\n",
    "    logger.info(study.best_params)\n",
    "    logger.info(f\"Best CV Score: {study.best_value}\")\n",
    "    \n",
    "    return study.best_params\n",
    "\n",
    "# Execute Tuning\n",
    "# best_params = run_tuning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3292d4c0-46e8-4f00-9e20-a5bc44209cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-20 17:13:01,054 - INFO - Loading Data...\n",
      "2026-01-20 17:13:02,553 - INFO - Tuning on subsample: (50000, 315)\n",
      "2026-01-20 17:13:02,555 - INFO - Starting Optuna Study...\n",
      "\u001b[32m[I 2026-01-20 17:13:02,557]\u001b[0m A new study created in memory with name: no-name-4d4d49b8-0c44-4882-b597-a1ab8c2aa1ea\u001b[0m\n",
      "\u001b[32m[I 2026-01-20 17:13:16,612]\u001b[0m Trial 0 finished with value: 0.7679702815118082 and parameters: {'num_leaves': 43, 'max_depth': 4, 'min_child_samples': 44, 'reg_alpha': 0.202658648966017, 'reg_lambda': 1.8372838411425592, 'colsample_bytree': 0.9387612810596043, 'subsample': 0.9978715785481631}. Best is trial 0 with value: 0.7679702815118082.\u001b[0m\n",
      "\u001b[32m[I 2026-01-20 17:13:41,164]\u001b[0m Trial 1 finished with value: 0.7657342479740986 and parameters: {'num_leaves': 93, 'max_depth': 12, 'min_child_samples': 48, 'reg_alpha': 9.927225192291306, 'reg_lambda': 3.935138298315582, 'colsample_bytree': 0.9494356154163142, 'subsample': 0.5449153092554752}. Best is trial 0 with value: 0.7679702815118082.\u001b[0m\n",
      "\u001b[32m[I 2026-01-20 17:14:02,785]\u001b[0m Trial 2 finished with value: 0.7651697913612773 and parameters: {'num_leaves': 75, 'max_depth': 8, 'min_child_samples': 69, 'reg_alpha': 2.069353892032287, 'reg_lambda': 2.4328545675199855, 'colsample_bytree': 0.9749801165874779, 'subsample': 0.5101948338208698}. Best is trial 0 with value: 0.7679702815118082.\u001b[0m\n",
      "\u001b[32m[I 2026-01-20 17:14:13,907]\u001b[0m Trial 3 finished with value: 0.7674210907296809 and parameters: {'num_leaves': 60, 'max_depth': 3, 'min_child_samples': 55, 'reg_alpha': 0.18821724375961052, 'reg_lambda': 0.23075722436324045, 'colsample_bytree': 0.6823261131451512, 'subsample': 0.6806391924387399}. Best is trial 0 with value: 0.7679702815118082.\u001b[0m\n",
      "\u001b[32m[I 2026-01-20 17:14:29,131]\u001b[0m Trial 4 finished with value: 0.7684851707933841 and parameters: {'num_leaves': 42, 'max_depth': 7, 'min_child_samples': 62, 'reg_alpha': 0.9763447458873413, 'reg_lambda': 2.717249050902542, 'colsample_bytree': 0.7574339186492063, 'subsample': 0.791385683813145}. Best is trial 4 with value: 0.7684851707933841.\u001b[0m\n",
      "\u001b[32m[I 2026-01-20 17:14:47,281]\u001b[0m Trial 5 finished with value: 0.7641111175321793 and parameters: {'num_leaves': 70, 'max_depth': 8, 'min_child_samples': 68, 'reg_alpha': 0.5829866768844458, 'reg_lambda': 2.1617379523978015, 'colsample_bytree': 0.9372631649043315, 'subsample': 0.8141464448236664}. Best is trial 4 with value: 0.7684851707933841.\u001b[0m\n",
      "\u001b[32m[I 2026-01-20 17:15:06,101]\u001b[0m Trial 6 finished with value: 0.7669389728557551 and parameters: {'num_leaves': 69, 'max_depth': 11, 'min_child_samples': 48, 'reg_alpha': 2.2425584982503097, 'reg_lambda': 2.0948871214297577, 'colsample_bytree': 0.7481132435061546, 'subsample': 0.6995142290080709}. Best is trial 4 with value: 0.7684851707933841.\u001b[0m\n",
      "\u001b[32m[I 2026-01-20 17:15:18,742]\u001b[0m Trial 7 finished with value: 0.7678955627861151 and parameters: {'num_leaves': 52, 'max_depth': 3, 'min_child_samples': 71, 'reg_alpha': 0.17918273993939654, 'reg_lambda': 0.12709334976274636, 'colsample_bytree': 0.6576579899319122, 'subsample': 0.8566800982183558}. Best is trial 4 with value: 0.7684851707933841.\u001b[0m\n",
      "\u001b[32m[I 2026-01-20 17:15:31,442]\u001b[0m Trial 8 finished with value: 0.7690903341369526 and parameters: {'num_leaves': 74, 'max_depth': 3, 'min_child_samples': 47, 'reg_alpha': 1.1108731685821094, 'reg_lambda': 2.0637587366828654, 'colsample_bytree': 0.5973247710744635, 'subsample': 0.5691895716823744}. Best is trial 8 with value: 0.7690903341369526.\u001b[0m\n",
      "\u001b[32m[I 2026-01-20 17:15:43,400]\u001b[0m Trial 9 finished with value: 0.7661266413561174 and parameters: {'num_leaves': 76, 'max_depth': 4, 'min_child_samples': 39, 'reg_alpha': 0.15092547738964526, 'reg_lambda': 0.3803157927541269, 'colsample_bytree': 0.9324511686975714, 'subsample': 0.7596106628482743}. Best is trial 8 with value: 0.7690903341369526.\u001b[0m\n",
      "\u001b[32m[I 2026-01-20 17:16:00,734]\u001b[0m Trial 10 finished with value: 0.7695071266614759 and parameters: {'num_leaves': 99, 'max_depth': 6, 'min_child_samples': 15, 'reg_alpha': 7.7210411785141995, 'reg_lambda': 0.6604646329351423, 'colsample_bytree': 0.5329047798090465, 'subsample': 0.6098014100623919}. Best is trial 10 with value: 0.7695071266614759.\u001b[0m\n",
      "\u001b[32m[I 2026-01-20 17:16:14,032]\u001b[0m Trial 11 finished with value: 0.7702426804532511 and parameters: {'num_leaves': 21, 'max_depth': 6, 'min_child_samples': 10, 'reg_alpha': 9.00274667896534, 'reg_lambda': 0.5911759079052462, 'colsample_bytree': 0.5297447580554155, 'subsample': 0.6067047037782883}. Best is trial 11 with value: 0.7702426804532511.\u001b[0m\n",
      "\u001b[32m[I 2026-01-20 17:16:28,842]\u001b[0m Trial 12 finished with value: 0.7707485000051099 and parameters: {'num_leaves': 28, 'max_depth': 6, 'min_child_samples': 10, 'reg_alpha': 9.816071373534351, 'reg_lambda': 0.7341816822637873, 'colsample_bytree': 0.5002590849488997, 'subsample': 0.6247985173257339}. Best is trial 12 with value: 0.7707485000051099.\u001b[0m\n",
      "\u001b[32m[I 2026-01-20 17:16:43,842]\u001b[0m Trial 13 finished with value: 0.7700434920703131 and parameters: {'num_leaves': 22, 'max_depth': 6, 'min_child_samples': 12, 'reg_alpha': 4.682627918870651, 'reg_lambda': 0.7582225075432546, 'colsample_bytree': 0.5031364221351154, 'subsample': 0.638280127523939}. Best is trial 12 with value: 0.7707485000051099.\u001b[0m\n",
      "\u001b[32m[I 2026-01-20 17:16:55,839]\u001b[0m Trial 14 finished with value: 0.7704878091742818 and parameters: {'num_leaves': 21, 'max_depth': 10, 'min_child_samples': 97, 'reg_alpha': 4.055075621599651, 'reg_lambda': 0.42661567620587604, 'colsample_bytree': 0.5764742569071004, 'subsample': 0.6193660557181099}. Best is trial 12 with value: 0.7707485000051099.\u001b[0m\n",
      "\u001b[32m[I 2026-01-20 17:17:10,243]\u001b[0m Trial 15 finished with value: 0.7689744785741089 and parameters: {'num_leaves': 32, 'max_depth': 10, 'min_child_samples': 99, 'reg_alpha': 4.6471667637309295, 'reg_lambda': 9.5650070497593, 'colsample_bytree': 0.5950607248638087, 'subsample': 0.6963524365378789}. Best is trial 12 with value: 0.7707485000051099.\u001b[0m\n",
      "\u001b[32m[I 2026-01-20 17:17:21,615]\u001b[0m Trial 16 finished with value: 0.7684104076150562 and parameters: {'num_leaves': 33, 'max_depth': 10, 'min_child_samples': 98, 'reg_alpha': 4.099307177313364, 'reg_lambda': 0.2814351293569652, 'colsample_bytree': 0.5872944460364546, 'subsample': 0.6679725901639441}. Best is trial 12 with value: 0.7707485000051099.\u001b[0m\n",
      "\u001b[32m[I 2026-01-20 17:17:36,596]\u001b[0m Trial 17 finished with value: 0.7677300345547023 and parameters: {'num_leaves': 32, 'max_depth': 10, 'min_child_samples': 27, 'reg_alpha': 2.4645113357179387, 'reg_lambda': 0.1157210096884939, 'colsample_bytree': 0.7710544326467648, 'subsample': 0.5084859916360934}. Best is trial 12 with value: 0.7707485000051099.\u001b[0m\n",
      "\u001b[32m[I 2026-01-20 17:17:48,780]\u001b[0m Trial 18 finished with value: 0.769295721264928 and parameters: {'num_leaves': 20, 'max_depth': 9, 'min_child_samples': 87, 'reg_alpha': 5.767315851397297, 'reg_lambda': 1.1323318556124116, 'colsample_bytree': 0.6730793355746013, 'subsample': 0.8727138248567898}. Best is trial 12 with value: 0.7707485000051099.\u001b[0m\n",
      "\u001b[32m[I 2026-01-20 17:18:03,524]\u001b[0m Trial 19 finished with value: 0.7661050182218411 and parameters: {'num_leaves': 41, 'max_depth': 12, 'min_child_samples': 82, 'reg_alpha': 0.49254424369824035, 'reg_lambda': 0.3992674414007129, 'colsample_bytree': 0.842451045242227, 'subsample': 0.7362941338846266}. Best is trial 12 with value: 0.7707485000051099.\u001b[0m\n",
      "\u001b[32m[I 2026-01-20 17:18:19,792]\u001b[0m Trial 20 finished with value: 0.7663294643390154 and parameters: {'num_leaves': 53, 'max_depth': 7, 'min_child_samples': 30, 'reg_alpha': 3.3373123263866944, 'reg_lambda': 1.1954701655507887, 'colsample_bytree': 0.6295603108557727, 'subsample': 0.5812568004156977}. Best is trial 12 with value: 0.7707485000051099.\u001b[0m\n",
      "\u001b[32m[I 2026-01-20 17:18:35,049]\u001b[0m Trial 21 finished with value: 0.7709043573713391 and parameters: {'num_leaves': 26, 'max_depth': 5, 'min_child_samples': 21, 'reg_alpha': 8.069414717200658, 'reg_lambda': 0.5482549315171409, 'colsample_bytree': 0.5392681172683854, 'subsample': 0.6151966387267918}. Best is trial 21 with value: 0.7709043573713391.\u001b[0m\n",
      "\u001b[32m[I 2026-01-20 17:18:50,878]\u001b[0m Trial 22 finished with value: 0.7708147667359784 and parameters: {'num_leaves': 29, 'max_depth': 5, 'min_child_samples': 23, 'reg_alpha': 6.515657136895558, 'reg_lambda': 0.2013255994476176, 'colsample_bytree': 0.5525719965231066, 'subsample': 0.6299276974248433}. Best is trial 21 with value: 0.7709043573713391.\u001b[0m\n",
      "\u001b[32m[I 2026-01-20 17:19:08,025]\u001b[0m Trial 23 finished with value: 0.7698802579534224 and parameters: {'num_leaves': 31, 'max_depth': 5, 'min_child_samples': 23, 'reg_alpha': 7.171396212571944, 'reg_lambda': 0.19725299617277722, 'colsample_bytree': 0.5433972964698325, 'subsample': 0.6364833348770288}. Best is trial 21 with value: 0.7709043573713391.\u001b[0m\n",
      "\u001b[32m[I 2026-01-20 17:19:24,249]\u001b[0m Trial 24 finished with value: 0.7701311370869259 and parameters: {'num_leaves': 28, 'max_depth': 5, 'min_child_samples': 21, 'reg_alpha': 6.173256499425816, 'reg_lambda': 0.16995666773403645, 'colsample_bytree': 0.5108315450220126, 'subsample': 0.5651721296696469}. Best is trial 21 with value: 0.7709043573713391.\u001b[0m\n",
      "\u001b[32m[I 2026-01-20 17:19:35,587]\u001b[0m Trial 25 finished with value: 0.7675715745524349 and parameters: {'num_leaves': 38, 'max_depth': 5, 'min_child_samples': 34, 'reg_alpha': 1.2660139020549466, 'reg_lambda': 0.3138897099739915, 'colsample_bytree': 0.5608958163616512, 'subsample': 0.6624192196669462}. Best is trial 21 with value: 0.7709043573713391.\u001b[0m\n",
      "\u001b[32m[I 2026-01-20 17:19:47,940]\u001b[0m Trial 26 finished with value: 0.7691856748971203 and parameters: {'num_leaves': 48, 'max_depth': 4, 'min_child_samples': 18, 'reg_alpha': 3.0753131589400176, 'reg_lambda': 0.5253570809086471, 'colsample_bytree': 0.6231463454054305, 'subsample': 0.7318175695362585}. Best is trial 21 with value: 0.7709043573713391.\u001b[0m\n",
      "\u001b[32m[I 2026-01-20 17:20:06,943]\u001b[0m Trial 27 finished with value: 0.770100136842831 and parameters: {'num_leaves': 27, 'max_depth': 6, 'min_child_samples': 36, 'reg_alpha': 9.685027018553747, 'reg_lambda': 0.9313905126683917, 'colsample_bytree': 0.5000421735154367, 'subsample': 0.5408390244736214}. Best is trial 21 with value: 0.7709043573713391.\u001b[0m\n",
      "\u001b[32m[I 2026-01-20 17:20:22,853]\u001b[0m Trial 28 finished with value: 0.7692177186952914 and parameters: {'num_leaves': 37, 'max_depth': 5, 'min_child_samples': 23, 'reg_alpha': 5.631937310201796, 'reg_lambda': 0.15676420243266115, 'colsample_bytree': 0.7093483065240366, 'subsample': 0.5953054100333437}. Best is trial 21 with value: 0.7709043573713391.\u001b[0m\n",
      "\u001b[32m[I 2026-01-20 17:20:35,528]\u001b[0m Trial 29 finished with value: 0.7678762110626941 and parameters: {'num_leaves': 46, 'max_depth': 4, 'min_child_samples': 29, 'reg_alpha': 0.4173615413269624, 'reg_lambda': 1.4294955424847673, 'colsample_bytree': 0.8758682907861968, 'subsample': 0.9141184422333268}. Best is trial 21 with value: 0.7709043573713391.\u001b[0m\n",
      "2026-01-20 17:20:35,528 - INFO - --- BEST PARAMETERS ---\n",
      "2026-01-20 17:20:35,529 - INFO - {'num_leaves': 26, 'max_depth': 5, 'min_child_samples': 21, 'reg_alpha': 8.069414717200658, 'reg_lambda': 0.5482549315171409, 'colsample_bytree': 0.5392681172683854, 'subsample': 0.6151966387267918}\n",
      "2026-01-20 17:20:35,530 - INFO - Best CV Score: 0.7709043573713391\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'num_leaves': 26,\n",
       " 'max_depth': 5,\n",
       " 'min_child_samples': 21,\n",
       " 'reg_alpha': 8.069414717200658,\n",
       " 'reg_lambda': 0.5482549315171409,\n",
       " 'colsample_bytree': 0.5392681172683854,\n",
       " 'subsample': 0.6151966387267918}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params = run_tuning()\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a0f2ab2-d2c1-42a6-8dce-d8557320caa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class TargetEncoder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Encodes categorical features with the mean of the target variable.\n",
    "    Smoothing is applied to prevent overfitting on rare categories.\n",
    "    \"\"\"\n",
    "    def __init__(self, cols=None, smoothing=10):\n",
    "        self.cols = cols\n",
    "        self.smoothing = smoothing\n",
    "        self.maps = {}\n",
    "        self.global_mean = 0\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.global_mean = y.mean()\n",
    "        \n",
    "        for col in self.cols:\n",
    "            # Calculate stats\n",
    "            stats = y.groupby(X[col]).agg(['count', 'mean'])\n",
    "            counts = stats['count']\n",
    "            means = stats['mean']\n",
    "            \n",
    "            # Smooth the mean\n",
    "            # (count * mean + smoothing * global_mean) / (count + smoothing)\n",
    "            smooth = (counts * means + self.smoothing * self.global_mean) / (counts + self.smoothing)\n",
    "            self.maps[col] = smooth\n",
    "            \n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_out = X.copy()\n",
    "        for col in self.cols:\n",
    "            # Map values, fill unknown with global mean\n",
    "            X_out[col] = X_out[col].map(self.maps[col]).fillna(self.global_mean)\n",
    "        return X_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2ce5ed6-19fe-49a7-ab36-2378032cd66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_final_model(best_params):\n",
    "    logger.info(\"--- STARTING FINAL TRAINING ---\")\n",
    "    \n",
    "    df = pd.read_parquet(Config.INPUT_PATH)\n",
    "    X = df.drop(columns=['TARGET', 'SK_ID_CURR'])\n",
    "    y = df['TARGET']\n",
    "    \n",
    "    # Identify Categoricals for Target Encoding\n",
    "    # (We usually pick high-cardinality ones like Occupation, Organization)\n",
    "    cat_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    \n",
    "    folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=Config.SEED)\n",
    "    scores = []\n",
    "    \n",
    "    # Update params with lower Learning Rate for final run\n",
    "    final_params = best_params.copy()\n",
    "    final_params['learning_rate'] = 0.01  # Super slow learning for max precision\n",
    "    final_params['n_estimators'] = 10000  # Allow it to grow\n",
    "    final_params['objective'] = 'binary'\n",
    "    final_params['metric'] = 'auc'\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(folds.split(X, y)):\n",
    "        X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
    "        X_val, y_val = X.iloc[val_idx], y.iloc[val_idx]\n",
    "        \n",
    "        # 1. APPLY TARGET ENCODING (Inside the loop!)\n",
    "        encoder = TargetEncoder(cols=cat_cols)\n",
    "        X_train_enc = encoder.fit_transform(X_train, y_train)\n",
    "        X_val_enc = encoder.transform(X_val)\n",
    "        \n",
    "        # 2. TRAIN\n",
    "        model = lgb.LGBMClassifier(**final_params)\n",
    "        \n",
    "        callbacks = [\n",
    "            lgb.early_stopping(stopping_rounds=200),\n",
    "            lgb.log_evaluation(period=1000)\n",
    "        ]\n",
    "        \n",
    "        model.fit(\n",
    "            X_train_enc, y_train,\n",
    "            eval_set=[(X_val_enc, y_val)],\n",
    "            eval_names=['train', 'valid'],\n",
    "            eval_metric='auc',\n",
    "            callbacks=callbacks\n",
    "        )\n",
    "        \n",
    "        score = roc_auc_score(y_val, model.predict_proba(X_val_enc)[:, 1])\n",
    "        scores.append(score)\n",
    "        logger.info(f\"Fold {fold+1} AUC: {score:.4f}\")\n",
    "        \n",
    "    logger.info(f\"Final Mean AUC: {np.mean(scores):.4f}\")\n",
    "\n",
    "# Usage:\n",
    "# 1. Run Optuna to get `best_params`\n",
    "# 2. Pass `best_params` to `run_final_model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2eca8f6-c639-477c-a654-ea2e9973b35a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-20 17:21:49,281 - INFO - --- STARTING FINAL TRAINING ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[1000]\ttrain's auc: 0.773663\n",
      "[2000]\ttrain's auc: 0.780707\n",
      "[3000]\ttrain's auc: 0.783469\n",
      "[4000]\ttrain's auc: 0.784599\n",
      "[5000]\ttrain's auc: 0.78505\n",
      "Early stopping, best iteration is:\n",
      "[5260]\ttrain's auc: 0.785167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-20 17:25:56,677 - INFO - Fold 1 AUC: 0.7852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[1000]\ttrain's auc: 0.785529\n",
      "[2000]\ttrain's auc: 0.792017\n",
      "[3000]\ttrain's auc: 0.794191\n",
      "[4000]\ttrain's auc: 0.795014\n",
      "Early stopping, best iteration is:\n",
      "[4179]\ttrain's auc: 0.795064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-20 17:29:35,425 - INFO - Fold 2 AUC: 0.7951\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[1000]\ttrain's auc: 0.774153\n",
      "[2000]\ttrain's auc: 0.781024\n",
      "[3000]\ttrain's auc: 0.783107\n",
      "[4000]\ttrain's auc: 0.784057\n",
      "[5000]\ttrain's auc: 0.784612\n",
      "Early stopping, best iteration is:\n",
      "[5360]\ttrain's auc: 0.784802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-20 17:34:11,740 - INFO - Fold 3 AUC: 0.7848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[1000]\ttrain's auc: 0.784065\n",
      "[2000]\ttrain's auc: 0.788487\n",
      "[3000]\ttrain's auc: 0.790298\n",
      "[4000]\ttrain's auc: 0.790773\n",
      "Early stopping, best iteration is:\n",
      "[4116]\ttrain's auc: 0.790805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-20 17:37:43,443 - INFO - Fold 4 AUC: 0.7908\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[1000]\ttrain's auc: 0.775551\n",
      "[2000]\ttrain's auc: 0.782108\n",
      "[3000]\ttrain's auc: 0.784159\n",
      "[4000]\ttrain's auc: 0.785356\n",
      "Early stopping, best iteration is:\n",
      "[4593]\ttrain's auc: 0.785726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-20 17:41:56,483 - INFO - Fold 5 AUC: 0.7857\n",
      "2026-01-20 17:41:56,485 - INFO - Final Mean AUC: 0.7883\n"
     ]
    }
   ],
   "source": [
    "run_final_model(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46ecc6d-b440-4d75-b006-cc9685d6443a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
