{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6176136-21a1-4694-be3e-369cbe66d8ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-20 12:51:48,764 - INFO - Notebook 07 Initialized.\n"
     ]
    }
   ],
   "source": [
    "# --- NOTEBOOK 07: THE PREVIOUS PLANET ---\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import logging\n",
    "\n",
    "# Logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class Config:\n",
    "    # Input Paths\n",
    "    PREV_APP_PATH = 'data/previous_application.csv'\n",
    "    INSTALLMENTS_PATH = 'data/installments_payments.csv'\n",
    "    POS_CASH_PATH = 'data/POS_CASH_balance.csv'\n",
    "    CREDIT_CARD_PATH = 'data/credit_card_balance.csv'\n",
    "    \n",
    "    # We load the output of Notebook 06\n",
    "    MAIN_DATA_PATH = 'train_bureau_merged.parquet'\n",
    "    \n",
    "    OUTPUT_PATH = 'train_full_merged.parquet'\n",
    "\n",
    "logger.info(\"Notebook 07 Initialized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b3f5f80-d24b-4fa7-b8d7-5cd8a831bde4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-20 12:52:54,030 - INFO - Loading Installments Payments...\n",
      "2026-01-20 12:53:12,424 - INFO - Aggregating Installments by User...\n",
      "2026-01-20 12:53:14,755 - INFO - Installments Aggregated. Shape: (339587, 10)\n"
     ]
    }
   ],
   "source": [
    "def process_installments():\n",
    "    logger.info(\"Loading Installments Payments...\")\n",
    "    ins = pd.read_csv(Config.INSTALLMENTS_PATH)\n",
    "    \n",
    "    # 1. Feature Engineering (The \"Bad Behavior\" Flags)\n",
    "    # Days Late: If they paid 5 days after due date. (Negative numbers = Early payment)\n",
    "    ins['DPD'] = ins['DAYS_ENTRY_PAYMENT'] - ins['DAYS_INSTALMENT']\n",
    "    ins['DPD'] = ins['DPD'].apply(lambda x: x if x > 0 else 0) # Only care about Late, not Early\n",
    "    \n",
    "    # Amount Underpaid: If they owed 100 but paid 90.\n",
    "    ins['AMT_UNDERPAID'] = ins['AMT_INSTALMENT'] - ins['AMT_PAYMENT']\n",
    "    ins['AMT_UNDERPAID'] = ins['AMT_UNDERPAID'].apply(lambda x: x if x > 0 else 0)\n",
    "    \n",
    "    # 2. Aggregations by USER (SK_ID_CURR)\n",
    "    # We want to know: \"Max days late\", \"Total amount unpaid\", \"Average payment size\"\n",
    "    agg_dict = {\n",
    "        'DPD': ['max', 'mean', 'sum'],\n",
    "        'AMT_UNDERPAID': ['max', 'mean', 'sum'],\n",
    "        'AMT_PAYMENT': ['mean', 'sum'],\n",
    "        'NUM_INSTALMENT_VERSION': ['nunique'] # Did they change the loan terms? (Refinance)\n",
    "    }\n",
    "    \n",
    "    logger.info(\"Aggregating Installments by User...\")\n",
    "    ins_agg = ins.groupby('SK_ID_CURR').agg(agg_dict)\n",
    "    \n",
    "    # Flatten Columns\n",
    "    ins_agg.columns = [f\"INS_{c[0]}_{c[1].upper()}\" for c in ins_agg.columns]\n",
    "    \n",
    "    # Count of installments (History Length)\n",
    "    ins_agg['INS_COUNT'] = ins.groupby('SK_ID_CURR').size()\n",
    "    \n",
    "    logger.info(f\"Installments Aggregated. Shape: {ins_agg.shape}\")\n",
    "    del ins\n",
    "    gc.collect()\n",
    "    return ins_agg\n",
    "\n",
    "# Execute\n",
    "ins_agg = process_installments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c711515d-cd14-41be-972e-853db2f86c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-20 12:53:24,740 - INFO - Loading POS Cash Balance...\n",
      "2026-01-20 12:53:30,273 - INFO - Aggregating POS by User...\n",
      "2026-01-20 12:53:33,303 - INFO - Loading Credit Card Balance...\n",
      "2026-01-20 12:53:38,663 - INFO - Aggregating Credit Card by User...\n"
     ]
    }
   ],
   "source": [
    "def process_pos_and_cc():\n",
    "    # --- A. POS CASH ---\n",
    "    logger.info(\"Loading POS Cash Balance...\")\n",
    "    pos = pd.read_csv(Config.POS_CASH_PATH)\n",
    "    \n",
    "    # One-Hot Encode Contract Status (Active, Completed, Signed)\n",
    "    pos_cats = pd.get_dummies(pos['NAME_CONTRACT_STATUS'], prefix='POS')\n",
    "    pos = pd.concat([pos, pos_cats], axis=1)\n",
    "    \n",
    "    # Aggregate\n",
    "    agg_dict = {col: ['mean'] for col in pos_cats.columns}\n",
    "    agg_dict['SK_DPD'] = ['max', 'mean'] # Days Past Due on POS\n",
    "    \n",
    "    logger.info(\"Aggregating POS by User...\")\n",
    "    pos_agg = pos.groupby('SK_ID_CURR').agg(agg_dict)\n",
    "    pos_agg.columns = [f\"POS_{c[0]}_{c[1].upper()}\" for c in pos_agg.columns]\n",
    "    pos_agg['POS_COUNT'] = pos.groupby('SK_ID_CURR').size()\n",
    "    \n",
    "    del pos, pos_cats\n",
    "    gc.collect()\n",
    "    \n",
    "    # --- B. CREDIT CARD ---\n",
    "    logger.info(\"Loading Credit Card Balance...\")\n",
    "    cc = pd.read_csv(Config.CREDIT_CARD_PATH)\n",
    "    \n",
    "    # Key Metrics: Balance, Drawings (Cash withdrawals), Limit usage\n",
    "    cc_agg_dict = {\n",
    "        'AMT_BALANCE': ['mean', 'max'],\n",
    "        'AMT_DRAWINGS_ATM_CURRENT': ['mean', 'sum'], # Taking cash out is risky!\n",
    "        'AMT_CREDIT_LIMIT_ACTUAL': ['mean'],\n",
    "        'SK_DPD': ['max', 'mean']\n",
    "    }\n",
    "    \n",
    "    logger.info(\"Aggregating Credit Card by User...\")\n",
    "    cc_agg = cc.groupby('SK_ID_CURR').agg(cc_agg_dict)\n",
    "    cc_agg.columns = [f\"CC_{c[0]}_{c[1].upper()}\" for c in cc_agg.columns]\n",
    "    cc_agg['CC_COUNT'] = cc.groupby('SK_ID_CURR').size()\n",
    "    \n",
    "    del cc\n",
    "    gc.collect()\n",
    "    \n",
    "    return pos_agg, cc_agg\n",
    "\n",
    "# Execute\n",
    "pos_agg, cc_agg = process_pos_and_cc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "562251ac-af13-4dcb-8e79-b364a25264d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-20 12:53:39,352 - INFO - Loading Previous Applications...\n",
      "2026-01-20 12:53:45,691 - INFO - Aggregating Previous Apps by User...\n",
      "2026-01-20 12:53:46,430 - INFO - Previous Apps Aggregated. Shape: (338857, 17)\n"
     ]
    }
   ],
   "source": [
    "def process_previous_applications():\n",
    "    logger.info(\"Loading Previous Applications...\")\n",
    "    prev = pd.read_csv(Config.PREV_APP_PATH)\n",
    "    \n",
    "    # 1. Contract Status (Approved vs Refused)\n",
    "    prev_cats = pd.get_dummies(prev['NAME_CONTRACT_STATUS'], prefix='PREV')\n",
    "    prev = pd.concat([prev, prev_cats], axis=1)\n",
    "    \n",
    "    # 2. Aggregations\n",
    "    # We want counts of Refusals and Mean Amounts\n",
    "    num_cols = ['AMT_ANNUITY', 'AMT_APPLICATION', 'AMT_CREDIT', 'AMT_DOWN_PAYMENT']\n",
    "    agg_dict = {col: ['min', 'max', 'mean'] for col in num_cols}\n",
    "    \n",
    "    # Add Categorical Means (e.g., % of time Refused)\n",
    "    for cat in prev_cats.columns:\n",
    "        agg_dict[cat] = ['mean']\n",
    "        \n",
    "    logger.info(\"Aggregating Previous Apps by User...\")\n",
    "    prev_agg = prev.groupby('SK_ID_CURR').agg(agg_dict)\n",
    "    prev_agg.columns = [f\"PREV_{c[0]}_{c[1].upper()}\" for c in prev_agg.columns]\n",
    "    \n",
    "    # Count total previous apps\n",
    "    prev_agg['PREV_APP_COUNT'] = prev.groupby('SK_ID_CURR').size()\n",
    "    \n",
    "    logger.info(f\"Previous Apps Aggregated. Shape: {prev_agg.shape}\")\n",
    "    del prev\n",
    "    gc.collect()\n",
    "    return prev_agg\n",
    "\n",
    "# Execute\n",
    "prev_agg = process_previous_applications()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "199a3e78-1ed1-4675-ae42-f7425ed4adb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-20 12:53:51,129 - INFO - Loading Main Data from train_bureau_merged.parquet...\n",
      "2026-01-20 12:53:52,550 - INFO - Final Shape: (307506, 317)\n",
      "2026-01-20 12:53:52,552 - INFO - Added 47 features from Previous History.\n",
      "2026-01-20 12:53:52,553 - INFO - Saving to train_full_merged.parquet...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def join_all_planets(ins_agg, pos_agg, cc_agg, prev_agg):\n",
    "    logger.info(f\"Loading Main Data from {Config.MAIN_DATA_PATH}...\")\n",
    "    df_main = pd.read_parquet(Config.MAIN_DATA_PATH)\n",
    "    \n",
    "    original_cols = df_main.shape[1]\n",
    "    \n",
    "    # Sequential Merges (Left Joins)\n",
    "    df = df_main.merge(ins_agg, on='SK_ID_CURR', how='left')\n",
    "    df = df.merge(pos_agg, on='SK_ID_CURR', how='left')\n",
    "    df = df.merge(cc_agg, on='SK_ID_CURR', how='left')\n",
    "    df = df.merge(prev_agg, on='SK_ID_CURR', how='left')\n",
    "    \n",
    "    new_cols = df.shape[1]\n",
    "    logger.info(f\"Final Shape: {df.shape}\")\n",
    "    logger.info(f\"Added {new_cols - original_cols} features from Previous History.\")\n",
    "    \n",
    "    logger.info(f\"Saving to {Config.OUTPUT_PATH}...\")\n",
    "    df.to_parquet(Config.OUTPUT_PATH, index=False)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Execute\n",
    "df_final = join_all_planets(ins_agg, pos_agg, cc_agg, prev_agg)\n",
    "\n",
    "# Clean up to prevent RAM crash\n",
    "del ins_agg, pos_agg, cc_agg, prev_agg\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f09b9e05-d78f-41d6-934f-876fbee9c22f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307506, 317)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
